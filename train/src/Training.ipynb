{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging \n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6701168\r\n",
      "drwxr-xr-x  20 i851894  1694527156         640 Sep 13 05:37 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  23 i851894  1694527156         736 Sep 12 21:14 \u001b[34m..\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   3 i851894  1694527156          96 Sep 12 21:40 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 i851894  1694527156       21404 Sep 12 22:02 Training.ipynb\r\n",
      "drwxr-xr-x   3 i851894  1694527156          96 Sep 12 21:40 \u001b[34m__pycache__\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 i851894  1694527156      483007 Sep 12 21:52 body_pp.dpkl\r\n",
      "-rw-r--r--@  1 i851894  1694527156  2852401417 Jan 17  2018 github_issues.csv\r\n",
      "-rw-r--r--   1 i851894  1694527156    72133256 Sep 12 21:54 seq2seq_model_tutorial.h5\r\n",
      "-rw-r--r--   1 i851894  1694527156       14145 Sep 12 21:38 seq2seq_utils.py\r\n",
      "-rw-r--r--   1 i851894  1694527156      172604 Sep 12 21:52 title_pp.dpkl\r\n",
      "-rw-r--r--   1 i851894  1694527156      504128 Sep 12 21:52 train_body_vecs.npy\r\n",
      "-rw-r--r--   1 i851894  1694527156       86528 Sep 12 21:52 train_title_vecs.npy\r\n",
      "-rw-r--r--   1 i851894  1694527156    72133256 Sep 12 21:53 tutorial_seq2seq.epoch01-val7.33981.hdf5\r\n",
      "-rw-r--r--   1 i851894  1694527156    72133256 Sep 12 21:53 tutorial_seq2seq.epoch02-val6.62132.hdf5\r\n",
      "-rw-r--r--   1 i851894  1694527156    72133256 Sep 12 21:53 tutorial_seq2seq.epoch03-val6.15946.hdf5\r\n",
      "-rw-r--r--   1 i851894  1694527156    72133256 Sep 12 21:54 tutorial_seq2seq.epoch04-val5.82226.hdf5\r\n",
      "-rw-r--r--   1 i851894  1694527156    72133256 Sep 12 21:54 tutorial_seq2seq.epoch05-val5.58255.hdf5\r\n",
      "-rw-r--r--   1 i851894  1694527156    72133256 Sep 12 21:54 tutorial_seq2seq.epoch06-val5.36982.hdf5\r\n",
      "-rw-r--r--   1 i851894  1694527156    72133256 Sep 12 21:54 tutorial_seq2seq.epoch07-val5.25294.hdf5\r\n",
      "-rw-r--r--   1 i851894  1694527156         295 Sep 12 21:54 tutorial_seq2seq.log\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "Spli data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4,798,937 rows 3 columns\n",
      "Test: 533,216 rows 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1063994</th>\n",
       "      <td>\"https://github.com/NutritionMate/Nutrition.Information.Api/issues/90\"</td>\n",
       "      <td>as an administrator of the nutrition information api repository, i want new issues to be automatically populated with the definition of ready template, so that it is never accidentally forgotten.</td>\n",
       "      <td>as an administrator of the nutrition information api repository, i want new issues to be automatically populated with the definition of ready template, so that it is never accidentally forgotten. given a new issue, then automatically populate the description with the definition of ready template. do this by using https://github.com/blog/2111-issue-and-pull-request-templates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277470</th>\n",
       "      <td>\"https://github.com/ITS-UofIowa/its.uiowa.edu/issues/61\"</td>\n",
       "      <td>change lynda.com links header to lynda video tutorials on info centers</td>\n",
       "      <td>if lynda video links are added to an info center, lynda.com links is the header displayed above the links. can this be changed to lynda vido tutorials ? i think the latter is a better descriptor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564648</th>\n",
       "      <td>\"https://github.com/ValerioLyndon/MAL-Public-List-Designs/issues/13\"</td>\n",
       "      <td>clarity - priority location and functionality is kind of a nuisance right now.</td>\n",
       "      <td>the hovering to display is annoying and could be improved. ! 2017-08-23 - 22 52 20 https://user-images.githubusercontent.com/29792052/29651456-b7093836-8855-11e7-9cb1-9c6dd5b638a4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      issue_url  \\\n",
       "1063994  \"https://github.com/NutritionMate/Nutrition.Information.Api/issues/90\"   \n",
       "5277470                \"https://github.com/ITS-UofIowa/its.uiowa.edu/issues/61\"   \n",
       "1564648    \"https://github.com/ValerioLyndon/MAL-Public-List-Designs/issues/13\"   \n",
       "\n",
       "                                                                                                                                                                                                 issue_title  \\\n",
       "1063994  as an administrator of the nutrition information api repository, i want new issues to be automatically populated with the definition of ready template, so that it is never accidentally forgotten.   \n",
       "5277470                                                                                                                               change lynda.com links header to lynda video tutorials on info centers   \n",
       "1564648                                                                                                                       clarity - priority location and functionality is kind of a nuisance right now.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                             body  \n",
       "1063994  as an administrator of the nutrition information api repository, i want new issues to be automatically populated with the definition of ready template, so that it is never accidentally forgotten. given a new issue, then automatically populate the description with the definition of ready template. do this by using https://github.com/blog/2111-issue-and-pull-request-templates  \n",
       "5277470                                                                                                                                                                                       if lynda video links are added to an info center, lynda.com links is the header displayed above the links. can this be changed to lynda vido tutorials ? i think the latter is a better descriptor.  \n",
       "1564648                                                                                                                                                                                                   the hovering to display is annoying and could be improved. ! 2017-08-23 - 22 52 20 https://user-images.githubusercontent.com/29792052/29651456-b7093836-8855-11e7-9cb1-9c6dd5b638a4.png  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'github_issues.csv'\n",
    "\n",
    "use_sample_data=False\n",
    "\n",
    "if use_sample_data:\n",
    "    training_data_size=2000\n",
    "    traindf, testdf = train_test_split(pd.read_csv(data_file).sample(n=training_data_size), \n",
    "                                   test_size=.10)\n",
    "else:\n",
    "    traindf, testdf = train_test_split(pd.read_csv(data_file),test_size=.10)\n",
    "\n",
    "#print out stats about shape of data\n",
    "print(f'Train: {traindf.shape[0]:,} rows {traindf.shape[1]:,} columns')\n",
    "print(f'Test: {testdf.shape[0]:,} rows {testdf.shape[1]:,} columns')\n",
    "\n",
    "# preview data\n",
    "traindf.head(3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as an administrator of the nutrition information api repository, i want new issues to be automatically populated with the definition of ready template, so that it is never accidentally forgotten. given a new issue, then automatically populate the description with the definition of ready template. do this by using https://github.com/blog/2111-issue-and-pull-request-templates'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_body_raw = traindf.body.tolist()\n",
    "train_title_raw = traindf.issue_title.tolist()\n",
    "#preview output of first element\n",
    "train_body_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from ktext.preprocess import processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:....tokenizing data\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in process_text\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in <listcomp>\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 57, in textacy_cleaner\n",
      "    no_accents=True)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 233, in preprocess_text\n",
      "    text = remove_accents(text, method='unicode')\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 169, in remove_accents\n",
      "    return ''.join(c for c in unicodedata.normalize('NFKD', text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 170, in <genexpr>\n",
      "    if not unicodedata.combining(c))\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in process_text\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "Process ForkPoolWorker-6:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in <listcomp>\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 57, in textacy_cleaner\n",
      "    no_accents=True)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 217, in preprocess_text\n",
      "    text = fix_bad_unicode(text, normalization='NFC')\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 38, in fix_bad_unicode\n",
      "    return fix_text(text, normalization=normalization)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/__init__.py\", line 183, in fix_text\n",
      "    normalization=normalization\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/__init__.py\", line 273, in fix_text_segment\n",
      "    text = fixes.fix_encoding(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/fixes.py\", line 110, in fix_encoding\n",
      "    text, _ = fix_encoding_and_explain(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/fixes.py\", line 145, in fix_encoding_and_explain\n",
      "    best_cost = text_cost(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/badness.py\", line 162, in text_cost\n",
      "    return sequence_weirdness(text) + len(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/badness.py\", line 149, in sequence_weirdness\n",
      "    weirdness = len(WEIRDNESS_RE.findall(chars_to_classes(text2)))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "Process ForkPoolWorker-5:\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in process_text\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in <listcomp>\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 57, in textacy_cleaner\n",
      "    no_accents=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 239, in preprocess_text\n",
      "    text = normalize_whitespace(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 58, in normalize_whitespace\n",
      "    return constants.NONBREAKING_SPACE_REGEX.sub(' ', constants.LINEBREAK_REGEX.sub(r'\\n', text)).strip()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in process_text\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in <listcomp>\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 57, in textacy_cleaner\n",
      "    no_accents=True)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 221, in preprocess_text\n",
      "    text = replace_urls(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 84, in replace_urls\n",
      "    return constants.URL_REGEX.sub(replace_with, constants.SHORT_URL_REGEX.sub(replace_with, text))\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in process_text\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in <listcomp>\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 57, in textacy_cleaner\n",
      "    no_accents=True)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 217, in preprocess_text\n",
      "    text = fix_bad_unicode(text, normalization='NFC')\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 38, in fix_bad_unicode\n",
      "    return fix_text(text, normalization=normalization)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/__init__.py\", line 183, in fix_text\n",
      "    normalization=normalization\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/__init__.py\", line 273, in fix_text_segment\n",
      "    text = fixes.fix_encoding(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/fixes.py\", line 110, in fix_encoding\n",
      "    text, _ = fix_encoding_and_explain(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/fixes.py\", line 145, in fix_encoding_and_explain\n",
      "    best_cost = text_cost(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/badness.py\", line 162, in text_cost\n",
      "    return sequence_weirdness(text) + len(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/badness.py\", line 149, in sequence_weirdness\n",
      "    weirdness = len(WEIRDNESS_RE.findall(chars_to_classes(text2)))\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in process_text\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in <listcomp>\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 57, in textacy_cleaner\n",
      "    no_accents=True)\n",
      "Process ForkPoolWorker-3:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 217, in preprocess_text\n",
      "    text = fix_bad_unicode(text, normalization='NFC')\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 38, in fix_bad_unicode\n",
      "    return fix_text(text, normalization=normalization)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/__init__.py\", line 183, in fix_text\n",
      "    normalization=normalization\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/__init__.py\", line 273, in fix_text_segment\n",
      "    text = fixes.fix_encoding(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/fixes.py\", line 110, in fix_encoding\n",
      "    text, _ = fix_encoding_and_explain(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/fixes.py\", line 152, in fix_encoding_and_explain\n",
      "    cost = text_cost(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/badness.py\", line 162, in text_cost\n",
      "    return sequence_weirdness(text) + len(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in process_text\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/badness.py\", line 149, in sequence_weirdness\n",
      "    weirdness = len(WEIRDNESS_RE.findall(chars_to_classes(text2)))\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in <listcomp>\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 57, in textacy_cleaner\n",
      "    no_accents=True)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 217, in preprocess_text\n",
      "    text = fix_bad_unicode(text, normalization='NFC')\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 38, in fix_bad_unicode\n",
      "    return fix_text(text, normalization=normalization)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/__init__.py\", line 183, in fix_text\n",
      "    normalization=normalization\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/__init__.py\", line 277, in fix_text_segment\n",
      "    text = fixes.fix_latin_ligatures(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ftfy/fixes.py\", line 381, in fix_latin_ligatures\n",
      "    return text.translate(LIGATURES)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in process_text\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 90, in <listcomp>\n",
      "    return [tokenizer(cleaner(doc)) for doc in text]\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\", line 57, in textacy_cleaner\n",
      "    no_accents=True)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 221, in preprocess_text\n",
      "    text = replace_urls(text)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/textacy/preprocess.py\", line 84, in replace_urls\n",
      "    return constants.URL_REGEX.sub(replace_with, constants.SHORT_URL_REGEX.sub(replace_with, text))\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/queues.py\", line 337, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/queues.py\", line 337, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/queues.py\", line 337, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/queues.py\", line 337, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/queues.py\", line 337, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/queues.py\", line 337, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/queues.py\", line 337, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/queues.py\", line 338, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/synchronize.py\", line 102, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/connection.py\", line 219, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/connection.py\", line 410, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/i851894/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/connection.py\", line 382, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\u001b[0m in \u001b[0;36mapply_parallel\u001b[0;34m(func, data, cpu_cores)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mtransformed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mtokenized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tokenized_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'...fit is finished, beginning transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, return_tokenized_data)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'....tokenizing data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mtokenized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_process_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_maxlen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\u001b[0m in \u001b[0;36mparallel_process_text\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    233\u001b[0m                                                 end_tok=self.end_tok)\n\u001b[1;32m    234\u001b[0m         \u001b[0mn_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mflattenlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_doc_length_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/ktext/preprocess.py\u001b[0m in \u001b[0;36mapply_parallel\u001b[0;34m(func, data, cpu_cores)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransformed_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "%%time\n",
    "# Clean, tokenize, and apply padding / truncating such that each document length = 70\n",
    "#  also, retain only the top 8,000 words in the vocabulary and set the remaining words\n",
    "#  to 1 which will become common index for rare words \n",
    "body_pp = processor(keep_n=8000, padding_maxlen=70)\n",
    "train_body_vecs = body_pp.fit_transform(train_body_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at one example of processed issue bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\noriginal string:\\n', train_body_raw[0], '\\n')\n",
    "print('after pre-processing:\\n', train_body_vecs[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a text processor for the titles, with some different parameters\n",
    "#  append_indicators = True appends the tokens '_start_' and '_end_' to each\n",
    "#                      document\n",
    "#  padding = 'post' means that zero padding is appended to the end of the \n",
    "#             of the document (as opposed to the default which is 'pre')\n",
    "title_pp = processor(append_indicators=True, keep_n=4500, \n",
    "                     padding_maxlen=12, padding ='post')\n",
    "\n",
    "# process the title data\n",
    "train_title_vecs = title_pp.fit_transform(train_title_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at one example of processed issue titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\noriginal string:\\n', train_title_raw[0])\n",
    "print('after pre-processing:\\n', train_title_vecs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle this vectors for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as dpickle\n",
    "import numpy as np\n",
    "\n",
    "# Save the preprocessor\n",
    "with open('body_pp.dpkl', 'wb') as f:\n",
    "    dpickle.dump(body_pp, f)\n",
    "\n",
    "with open('title_pp.dpkl', 'wb') as f:\n",
    "    dpickle.dump(title_pp, f)\n",
    "\n",
    "# Save the processed data\n",
    "np.save('train_title_vecs.npy', train_title_vecs)\n",
    "np.save('train_body_vecs.npy', train_body_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "Load the data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_utils import load_decoder_inputs, load_encoder_inputs, load_text_processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, doc_length = load_encoder_inputs('train_body_vecs.npy')\n",
    "decoder_input_data, decoder_target_data = load_decoder_inputs('train_title_vecs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens, body_pp = load_text_processor('body_pp.dpkl')\n",
    "num_decoder_tokens, title_pp = load_text_processor('title_pp.dpkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, BatchNormalization\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arbitrarly set latent dimension for embedding and hidden units\n",
    "latent_dim = 300\n",
    "\n",
    "##### Define Model Architecture ######\n",
    "\n",
    "########################\n",
    "#### Encoder Model ####\n",
    "encoder_inputs = Input(shape=(doc_length,), name='Encoder-Input')\n",
    "\n",
    "# Word embeding for encoder (ex: Issue Body)\n",
    "x = Embedding(num_encoder_tokens, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
    "x = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n",
    "\n",
    "# We do not need the `encoder_output` just the hidden state.\n",
    "_, state_h = GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x)\n",
    "\n",
    "# Encapsulate the encoder as a separate entity so we can just \n",
    "#  encode without decoding if we want to.\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n",
    "\n",
    "seq2seq_encoder_out = encoder_model(encoder_inputs)\n",
    "\n",
    "########################\n",
    "#### Decoder Model ####\n",
    "decoder_inputs = Input(shape=(None,), name='Decoder-Input')  # for teacher forcing\n",
    "\n",
    "# Word Embedding For Decoder (ex: Issue Titles)\n",
    "dec_emb = Embedding(num_decoder_tokens, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
    "dec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
    "\n",
    "# Set up the decoder, using `decoder_state_input` as initial state.\n",
    "decoder_gru = GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\n",
    "decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\n",
    "x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
    "\n",
    "# Dense layer for prediction\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Final-Output-Dense')\n",
    "decoder_outputs = decoder_dense(x)\n",
    "\n",
    "########################\n",
    "#### Seq2Seq Model ####\n",
    "\n",
    "#seq2seq_decoder_out = decoder_model([decoder_inputs, seq2seq_encoder_out])\n",
    "seq2seq_Model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "seq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_utils import viz_model_architecture\n",
    "seq2seq_Model.summary()\n",
    "viz_model_architecture(seq2seq_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "script_name_base = 'tutorial_seq2seq'\n",
    "csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "model_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n",
    "                                   save_best_only=True)\n",
    "\n",
    "batch_size = 1200\n",
    "epochs = 7\n",
    "history = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.12, callbacks=[csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "seq2seq_Model.save('seq2seq_model_tutorial.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Example Results on Holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_utils import Seq2Seq_Inference\n",
    "seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=body_pp,\n",
    "                                 decoder_preprocessor=title_pp,\n",
    "                                 seq2seq_model=seq2seq_Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method displays the predictions on random rows of the holdout set\n",
    "seq2seq_inf.demo_model_predictions(n=50, issue_df=testdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model : BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convenience function that generates predictions on holdout set and calculates BLEU Score\n",
    "\n",
    "bleu_score = seq2seq_inf.evaluate_model(holdout_bodies=testdf.body.tolist(), \n",
    "                                        holdout_titles=testdf.issue_title.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'BLEU Score (avg of BLUE 1-4) on Holdout Set: {bleu_score * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
